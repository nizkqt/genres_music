{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# path to json file that stores MFCCs and genre labels for each processed segment\n",
    "DATA_PATH = \"data_10.json\"\n",
    "\n",
    "def load_data(data_path):\n",
    "    \"\"\"Loads training dataset from json file.\n",
    "        :param data_path (str): Path to json file containing data\n",
    "        :return X (ndarray): Inputs\n",
    "        :return y (ndarray): Targets\n",
    "    \"\"\"\n",
    "\n",
    "    with open(data_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "\n",
    "    # convert lists to numpy arrays\n",
    "    X = np.array(data[\"mfcc\"])\n",
    "    y = np.array(data[\"labels\"])\n",
    "\n",
    "    print(\"Data succesfully loaded!\")\n",
    "\n",
    "    return  X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Data succesfully loaded!\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nflatten (Flatten)            (None, 1690)              0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               865792    \n_________________________________________________________________\ndense_1 (Dense)              (None, 256)               131328    \n_________________________________________________________________\ndense_2 (Dense)              (None, 64)                16448     \n_________________________________________________________________\ndense_3 (Dense)              (None, 10)                650       \n=================================================================\nTotal params: 1,014,218\nTrainable params: 1,014,218\nNon-trainable params: 0\n_________________________________________________________________\nTrain on 6997 samples, validate on 2999 samples\nEpoch 1/10\n6997/6997 [==============================] - 3s 378us/sample - loss: 7.5769 - accuracy: 0.3196 - val_loss: 3.7496 - val_accuracy: 0.3515\nEpoch 2/10\n6997/6997 [==============================] - 1s 214us/sample - loss: 2.9379 - accuracy: 0.4159 - val_loss: 2.8612 - val_accuracy: 0.3901\nEpoch 3/10\n6997/6997 [==============================] - 1s 211us/sample - loss: 2.0399 - accuracy: 0.4362 - val_loss: 2.1879 - val_accuracy: 0.3675\nEpoch 4/10\n6997/6997 [==============================] - 1s 211us/sample - loss: 1.7278 - accuracy: 0.4369 - val_loss: 2.0837 - val_accuracy: 0.4058\nEpoch 5/10\n6997/6997 [==============================] - 1s 212us/sample - loss: 1.4940 - accuracy: 0.5029 - val_loss: 2.1207 - val_accuracy: 0.4025\nEpoch 6/10\n6997/6997 [==============================] - 1s 211us/sample - loss: 1.4032 - accuracy: 0.5371 - val_loss: 2.0062 - val_accuracy: 0.4235\nEpoch 7/10\n6997/6997 [==============================] - 1s 213us/sample - loss: 1.3006 - accuracy: 0.5652 - val_loss: 2.0445 - val_accuracy: 0.4481\nEpoch 8/10\n6997/6997 [==============================] - 1s 211us/sample - loss: 1.1894 - accuracy: 0.5974 - val_loss: 1.9637 - val_accuracy: 0.4351\nEpoch 9/10\n6997/6997 [==============================] - 1s 212us/sample - loss: 1.1261 - accuracy: 0.6203 - val_loss: 1.9765 - val_accuracy: 0.4612\nEpoch 10/10\n6997/6997 [==============================] - 1s 209us/sample - loss: 0.9818 - accuracy: 0.6694 - val_loss: 2.0496 - val_accuracy: 0.4642\n"
    }
   ],
   "source": [
    "X, y = load_data(DATA_PATH)\n",
    "\n",
    "# create train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# build network topology\n",
    "model = keras.Sequential([\n",
    "\n",
    "        # input layer\n",
    "        keras.layers.Flatten(input_shape=(X.shape[1], X.shape[2])),\n",
    "\n",
    "        # 1st dense layer\n",
    "        keras.layers.Dense(512, activation='relu'),\n",
    "\n",
    "        # 2nd dense layer\n",
    "        keras.layers.Dense(256, activation='relu'),\n",
    "\n",
    "        # 3rd dense layer\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "\n",
    "        # output layer\n",
    "        keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "# compile model\n",
    "optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimiser,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "    # train model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 6997 samples, validate on 2999 samples\nEpoch 1/50\n6997/6997 [==============================] - 2s 217us/sample - loss: 0.9517 - accuracy: 0.6823 - val_loss: 1.9249 - val_accuracy: 0.4832\nEpoch 2/50\n6997/6997 [==============================] - 1s 208us/sample - loss: 0.8804 - accuracy: 0.7036 - val_loss: 2.0148 - val_accuracy: 0.4928\nEpoch 3/50\n6997/6997 [==============================] - 1s 210us/sample - loss: 0.7953 - accuracy: 0.7329 - val_loss: 2.0465 - val_accuracy: 0.4858\nEpoch 4/50\n6997/6997 [==============================] - 1s 209us/sample - loss: 0.7391 - accuracy: 0.7467 - val_loss: 1.9652 - val_accuracy: 0.5145\nEpoch 5/50\n6997/6997 [==============================] - 1s 209us/sample - loss: 0.7180 - accuracy: 0.7502 - val_loss: 2.0768 - val_accuracy: 0.5078\nEpoch 6/50\n6997/6997 [==============================] - 1s 207us/sample - loss: 0.6280 - accuracy: 0.7832 - val_loss: 2.0354 - val_accuracy: 0.5268\nEpoch 7/50\n6997/6997 [==============================] - 1s 207us/sample - loss: 0.5529 - accuracy: 0.8069 - val_loss: 2.0156 - val_accuracy: 0.5095\nEpoch 8/50\n6997/6997 [==============================] - 1s 207us/sample - loss: 0.5303 - accuracy: 0.8196 - val_loss: 1.9160 - val_accuracy: 0.5382\nEpoch 9/50\n6997/6997 [==============================] - 2s 217us/sample - loss: 0.5094 - accuracy: 0.8262 - val_loss: 2.2023 - val_accuracy: 0.5088\nEpoch 10/50\n6997/6997 [==============================] - 1s 213us/sample - loss: 0.4674 - accuracy: 0.8418 - val_loss: 2.2491 - val_accuracy: 0.5082\nEpoch 11/50\n6997/6997 [==============================] - 1s 209us/sample - loss: 0.4285 - accuracy: 0.8538 - val_loss: 2.2310 - val_accuracy: 0.5272\nEpoch 12/50\n6997/6997 [==============================] - 1s 207us/sample - loss: 0.4051 - accuracy: 0.8565 - val_loss: 2.1112 - val_accuracy: 0.5318\nEpoch 13/50\n6997/6997 [==============================] - 1s 212us/sample - loss: 0.3750 - accuracy: 0.8739 - val_loss: 2.2267 - val_accuracy: 0.5539\nEpoch 14/50\n6997/6997 [==============================] - 1s 214us/sample - loss: 0.3424 - accuracy: 0.8804 - val_loss: 2.0751 - val_accuracy: 0.5572\nEpoch 15/50\n6997/6997 [==============================] - 1s 211us/sample - loss: 0.2959 - accuracy: 0.9018 - val_loss: 2.1535 - val_accuracy: 0.5565\nEpoch 16/50\n6997/6997 [==============================] - 1s 208us/sample - loss: 0.2921 - accuracy: 0.8991 - val_loss: 2.3232 - val_accuracy: 0.5498\nEpoch 17/50\n6997/6997 [==============================] - 1s 208us/sample - loss: 0.2696 - accuracy: 0.9050 - val_loss: 2.2317 - val_accuracy: 0.5599\nEpoch 18/50\n6997/6997 [==============================] - 1s 212us/sample - loss: 0.2500 - accuracy: 0.9124 - val_loss: 2.1927 - val_accuracy: 0.5692\nEpoch 19/50\n6997/6997 [==============================] - 1s 208us/sample - loss: 0.2228 - accuracy: 0.9228 - val_loss: 2.2160 - val_accuracy: 0.5405\nEpoch 20/50\n6997/6997 [==============================] - 1s 207us/sample - loss: 0.2680 - accuracy: 0.9071 - val_loss: 2.1860 - val_accuracy: 0.5605\nEpoch 21/50\n6997/6997 [==============================] - 1s 211us/sample - loss: 0.2630 - accuracy: 0.9104 - val_loss: 2.3565 - val_accuracy: 0.5372\nEpoch 22/50\n6997/6997 [==============================] - 1s 209us/sample - loss: 0.2270 - accuracy: 0.9237 - val_loss: 2.3762 - val_accuracy: 0.5565\nEpoch 23/50\n6997/6997 [==============================] - 1s 210us/sample - loss: 0.1790 - accuracy: 0.9395 - val_loss: 2.2310 - val_accuracy: 0.5762\nEpoch 24/50\n6997/6997 [==============================] - 1s 214us/sample - loss: 0.1377 - accuracy: 0.9517 - val_loss: 2.3517 - val_accuracy: 0.5749\nEpoch 25/50\n6997/6997 [==============================] - 1s 209us/sample - loss: 0.1573 - accuracy: 0.9465 - val_loss: 2.4525 - val_accuracy: 0.5649\nEpoch 26/50\n6997/6997 [==============================] - 1s 211us/sample - loss: 0.1518 - accuracy: 0.9503 - val_loss: 2.3171 - val_accuracy: 0.5675\nEpoch 27/50\n6997/6997 [==============================] - 1s 212us/sample - loss: 0.2585 - accuracy: 0.9167 - val_loss: 2.5180 - val_accuracy: 0.5515\nEpoch 28/50\n6997/6997 [==============================] - 1s 209us/sample - loss: 0.2683 - accuracy: 0.9125 - val_loss: 2.4749 - val_accuracy: 0.5639\nEpoch 29/50\n6997/6997 [==============================] - 1s 208us/sample - loss: 0.1302 - accuracy: 0.9550 - val_loss: 2.4705 - val_accuracy: 0.5875\nEpoch 30/50\n6997/6997 [==============================] - 1s 209us/sample - loss: 0.1231 - accuracy: 0.9594 - val_loss: 2.5274 - val_accuracy: 0.5852\nEpoch 31/50\n6997/6997 [==============================] - 1s 212us/sample - loss: 0.1312 - accuracy: 0.9567 - val_loss: 2.7057 - val_accuracy: 0.5555\nEpoch 32/50\n6997/6997 [==============================] - 1s 212us/sample - loss: 0.0930 - accuracy: 0.9707 - val_loss: 2.7890 - val_accuracy: 0.5662\nEpoch 33/50\n6997/6997 [==============================] - 1s 214us/sample - loss: 0.1140 - accuracy: 0.9623 - val_loss: 2.4548 - val_accuracy: 0.5815\nEpoch 34/50\n6997/6997 [==============================] - 2s 220us/sample - loss: 0.1717 - accuracy: 0.9435 - val_loss: 2.6519 - val_accuracy: 0.5562\nEpoch 35/50\n6997/6997 [==============================] - 2s 218us/sample - loss: 0.1670 - accuracy: 0.9440 - val_loss: 2.4300 - val_accuracy: 0.5879\nEpoch 36/50\n6997/6997 [==============================] - 2s 216us/sample - loss: 0.0794 - accuracy: 0.9738 - val_loss: 2.5863 - val_accuracy: 0.5892\nEpoch 37/50\n6997/6997 [==============================] - 2s 225us/sample - loss: 0.0608 - accuracy: 0.9811 - val_loss: 2.7871 - val_accuracy: 0.5669\nEpoch 38/50\n6997/6997 [==============================] - 2s 222us/sample - loss: 0.0932 - accuracy: 0.9674 - val_loss: 2.6680 - val_accuracy: 0.5925\nEpoch 39/50\n6997/6997 [==============================] - 2s 215us/sample - loss: 0.2374 - accuracy: 0.9273 - val_loss: 2.6710 - val_accuracy: 0.5762\nEpoch 40/50\n6997/6997 [==============================] - 2s 216us/sample - loss: 0.1211 - accuracy: 0.9606 - val_loss: 2.5171 - val_accuracy: 0.5872\nEpoch 41/50\n6997/6997 [==============================] - 1s 210us/sample - loss: 0.0740 - accuracy: 0.9764 - val_loss: 2.6379 - val_accuracy: 0.5769\nEpoch 42/50\n6997/6997 [==============================] - 1s 209us/sample - loss: 0.1034 - accuracy: 0.9640 - val_loss: 2.7757 - val_accuracy: 0.5789\nEpoch 43/50\n6997/6997 [==============================] - 1s 210us/sample - loss: 0.1061 - accuracy: 0.9657 - val_loss: 2.7993 - val_accuracy: 0.5849\nEpoch 44/50\n6997/6997 [==============================] - 1s 212us/sample - loss: 0.0503 - accuracy: 0.9841 - val_loss: 2.7555 - val_accuracy: 0.5869\nEpoch 45/50\n6997/6997 [==============================] - 1s 209us/sample - loss: 0.1091 - accuracy: 0.9661 - val_loss: 2.9179 - val_accuracy: 0.5742\nEpoch 46/50\n6997/6997 [==============================] - 1s 210us/sample - loss: 0.2113 - accuracy: 0.9285 - val_loss: 2.8741 - val_accuracy: 0.5685\nEpoch 47/50\n6997/6997 [==============================] - 2s 218us/sample - loss: 0.0986 - accuracy: 0.9657 - val_loss: 2.6956 - val_accuracy: 0.5889\nEpoch 48/50\n6997/6997 [==============================] - 1s 210us/sample - loss: 0.0960 - accuracy: 0.9703 - val_loss: 2.7611 - val_accuracy: 0.5725\nEpoch 49/50\n6997/6997 [==============================] - 1s 208us/sample - loss: 0.0765 - accuracy: 0.9754 - val_loss: 2.6141 - val_accuracy: 0.5895\nEpoch 50/50\n6997/6997 [==============================] - 1s 209us/sample - loss: 0.0333 - accuracy: 0.9910 - val_loss: 2.7832 - val_accuracy: 0.6002\n"
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=32, epochs=50)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitthivmconda23b37608f7144fb0aec54a3bface4bbd",
   "display_name": "Python 3.7.7 64-bit ('thivm': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}